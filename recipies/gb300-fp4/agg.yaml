# Simple example to deploy DSR1 FP4 across 2 nodes in aggregated mode

name: "gb200-fp8-1p-4d-low-latency"

model:
  path: "dsfp4"
  container: "default-cu13"
  precision: "fp4"

resources:
  gpu_type: "gb300"
  agg_nodes: 2
  agg_workers: 1
  gpus_per_node: 4

backend:
  # this line spins up multiple frontend workers. set to false when doing agg
  enable_multiple_frontends: false

  aggregated_environment:
    TORCH_DISTRIBUTED_DEFAULT_TIMEOUT: "1800"
    PYTHONBUFFERED: "1"
    DYN_SKIP_SGLANG_LOG_FORMATTING: "1"
    NCCL_MNNVL_ENABLE: "1"
    NCCL_CUMEM_ENABLE: "1"
    SGLANG_ENABLE_JIT_DEEPGEMM: "false"

  sglang_config:
    aggregated:
      served-model-name: "deepseek-ai/DeepSeek-R1"
      model-path: "/model/"
      tensor-parallel-size: 8
      quantization: "modelopt_fp4"
      kv-cache-dtype: "fp8_e4m3"
      moe-runner-backend: "flashinfer_trtllm"
      attention-backend: "trtllm_mla"

benchmark:
  type: "sa-bench"
  isl: 1024
  osl: 1024
  concurrencies: "4x8x32x64x112x128"
  req_rate: "inf"